{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":60626,"status":"error","timestamp":1724027147807,"user":{"displayName":"x86_64 darwin","userId":"15445499627305928052"},"user_tz":-540},"id":"agOAty0Tfe6q","outputId":"18aea890-e466-4fdc-e18e-23e4ba922d69"},"outputs":[],"source":["import os\n","import cv2\n","import dlib\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import pickle\n","import random\n","import face_recognition\n","from PIL import Image, ImageDraw, ImageFont\n","from torchvision import models, transforms\n","from tqdm import tqdm\n","from ultralytics import YOLO\n","from mtcnn import MTCNN\n","import time\n","import matplotlib.pyplot as plt\n","from sklearn.metrics.pairwise import cosine_similarity\n","from scipy.spatial.distance import chebyshev, minkowski, mahalanobis, braycurtis\n","import piexif\n","from abc import ABC, abstractmethod # 추상 클래스\n","import io\n","import shutil\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/1 d:\\FinalProject\\Python\\Pybo0!CodeTest\\AiPredict\\Image\\test\\test_park_mind_problem\\113.jpg: 928x1280 3 faces, 1531.2ms\n","Speed: 452.8ms preprocess, 1531.2ms inference, 275.2ms postprocess per image at shape (1, 3, 928, 1280)\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 0s 109ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","4/4 [==============================] - 0s 3ms/step\n","1/1 [==============================] - 0s 130ms/step\n","113.jpg has been saved with modified metadata to d:\\FinalProject\\Python\\Pybo0!CodeTest\\AiPredict\\results\\detection_target\n","Processed d:\\FinalProject\\Python\\Pybo0!CodeTest\\AiPredict\\Image\\test\\test_park_mind_problem\\113.jpg\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n","\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n","\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n","\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."]}],"source":["\n","#\n","# 추상화: 얼굴 탐지기 인터페이스\n","class FaceDetector(ABC):\n","    @abstractmethod\n","    def detect_faces(self, image):\n","        pass\n","        #\n","    #\n","#\n","# Dlib 얼굴 탐지기 구현\n","class DlibFaceDetector(FaceDetector):\n","    def __init__(self, model_path):\n","        self.detector = dlib.cnn_face_detection_model_v1(model_path)\n","        #\n","    #\n","    def detect_faces(self, image):\n","        return [(d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom()) for d in self.detector(image, 1)]\n","        #\n","    #\n","#\n","# YOLO 얼굴 탐지기 구현\n","class YOLOFaceDetector(FaceDetector):\n","    def __init__(self, model_path):\n","        self.detector = YOLO(model_path)\n","        #\n","    #\n","    def detect_faces(self, image_path):\n","        results = self.detector.predict(image_path, conf=0.35, imgsz=1280, max_det=1000)\n","        boxes = []\n","        for result in results:\n","            boxes.extend([(int(box.xyxy[0][0]), int(box.xyxy[0][1]), int(box.xyxy[0][2]), int(box.xyxy[0][3])) for box in result.boxes])\n","        return boxes\n","        #\n","    #\n","#\n","# MTCNN 얼굴 탐지기 구현\n","class MTCNNFaceDetector(FaceDetector):\n","    def __init__(self):\n","        self.detector = MTCNN()\n","        #\n","    #\n","    def detect_faces(self, image):\n","        return [(f['box'][0], f['box'][1], f['box'][0] + f['box'][2], f['box'][1] + f['box'][3]) for f in self.detector.detect_faces(image)]\n","        #\n","    #\n","#\n","# 얼굴 탐지 관리자 클래스 - SRP를 따르고, 다형성 활용\n","class FaceDetectionManager:\n","    def __init__(self, detectors: list[FaceDetector]):\n","        self._detectors = detectors\n","        #\n","    #\n","    def detect_faces(self, image, image_path=None):\n","        all_faces = []\n","        for detector in self._detectors:\n","            if isinstance(detector, YOLOFaceDetector) and image_path:\n","                faces = detector.detect_faces(image_path)\n","            else:\n","                faces = detector.detect_faces(image)\n","                #\n","            #\n","            all_faces.extend(faces)\n","            #\n","        #\n","        non_max_suppressed_faces, _ = self.non_max_suppression(np.array(all_faces), np.ones(len(all_faces)), 0.6)\n","        return non_max_suppressed_faces\n","        #\n","    #\n","    @staticmethod\n","    def non_max_suppression(boxes, scores, overlapThresh):\n","        if len(boxes) == 0:\n","            return [], []\n","            #\n","        #\n","        boxes = boxes.astype(\"float\")\n","        pick = []\n","        x1 = boxes[:, 0]\n","        y1 = boxes[:, 1]\n","        x2 = boxes[:, 2]\n","        y2 = boxes[:, 3]\n","        #\n","        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n","        idxs = np.argsort(scores)\n","        #\n","        while len(idxs) > 0:\n","            last = len(idxs) - 1\n","            i = idxs[last]\n","            pick.append(i)\n","            #\n","            xx1 = np.maximum(x1[i], x1[idxs[:last]])\n","            yy1 = np.maximum(y1[i], y1[idxs[:last]])\n","            xx2 = np.minimum(x2[i], x2[idxs[:last]])\n","            yy2 = np.minimum(y2[i], y2[idxs[:last]])\n","            #\n","            w = np.maximum(0, xx2 - xx1 + 1)\n","            h = np.maximum(0, yy2 - yy1 + 1)\n","            #\n","            overlap = (w * h) / area[idxs[:last]]\n","            #\n","            idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n","            #\n","        #\n","        return boxes[pick].astype(\"int\"), scores[pick]\n","        #\n","    #\n","#\n","# 추상화: 예측기 인터페이스\n","class Predictor(ABC):\n","    @abstractmethod\n","    def predict(self, face_image):\n","        pass\n","        #\n","    #\n","#\n","# Age, Gender, Race Predictor 구현 - SRP 및 다형성\n","class FairFacePredictor(Predictor):\n","    def __init__(self, model_path):\n","        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        self.model = self._load_model(model_path)\n","        #\n","    #\n","    def _load_model(self, model_path):\n","        model = models.resnet34(pretrained=True)\n","        model.fc = nn.Linear(model.fc.in_features, 18)\n","        model.load_state_dict(torch.load(model_path, map_location=self.device))\n","        model = model.to(self.device)\n","        model.eval()\n","        return model\n","        #\n","    #\n","    def predict(self, face_image):\n","        trans = transforms.Compose([\n","            transforms.ToPILImage(),\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","        #\n","        try:\n","            face_image = trans(face_image).unsqueeze(0).to(self.device)\n","        except ValueError:\n","            print(\"Image is too small or corrupt, skipping prediction.\")\n","            return None, None, None\n","            #\n","        #\n","        with torch.no_grad():\n","            outputs = self.model(face_image).cpu().numpy().squeeze()\n","            #\n","        #\n","        race_pred = np.argmax(outputs[:4])\n","        gender_pred = np.argmax(outputs[7:9])\n","        age_pred = np.argmax(outputs[9:18])\n","        #\n","        return race_pred, gender_pred, age_pred\n","        #\n","    #\n","#\n","# 이미지 전처리 및 유틸리티 클래스 - SRP 및 캡슐화\n","class ImageProcessor:\n","    #\n","    @staticmethod\n","    # 이미지 리사이즈 및 패딩 함수\n","    def resize_and_pad(image, target_size):\n","        h, w, _ = image.shape\n","        scale = target_size / max(h, w)\n","        resized_img = cv2.resize(image, (int(w * scale), int(h * scale)))\n","        #\n","        delta_w = target_size - resized_img.shape[1]\n","        delta_h = target_size - resized_img.shape[0]\n","        top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n","        left, right = delta_w // 2, delta_w - (delta_w // 2)\n","        #\n","        color = [0, 0, 0]\n","        new_img = cv2.copyMakeBorder(resized_img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n","        #\n","        return new_img, scale, top, left\n","        #\n","    #\n","    @staticmethod\n","    # 한글 텍스트 그리기 함수\n","    def draw_text_korean(image, text, position, font_size, font_color=(255, 255, 255), thickness=1, background_color=(0, 0, 0)):\n","        # 텍스트가 없으면 이미지 그대로 반환\n","        if text == '':\n","            return image\n","            #\n","        #\n","        font = ImageFont.truetype(font_path, int(font_size))\n","        img_pil = Image.fromarray(image)\n","        draw = ImageDraw.Draw(img_pil)\n","        #\n","        # 텍스트 크기 측정\n","        text_bbox = draw.textbbox((0, 0), text, font=font)\n","        text_width = text_bbox[2] - text_bbox[0]\n","        text_height = text_bbox[3] - text_bbox[1]\n","        #\n","        # 텍스트에 맞춰 박스 크기 조정\n","        box_x0 = position[0] - 5\n","        box_y0 = position[1] - 5\n","        box_x1 = position[0] + text_width + 5\n","        box_y1 = position[1] + text_height + 5\n","        #\n","        # 이미지가 텍스트를 수용할 수 있도록 크기를 확장\n","        if box_x1 > image.shape[1] or box_y1 > image.shape[0]:\n","            new_width = max(box_x1, image.shape[1])\n","            new_height = max(box_y1, image.shape[0])\n","            extended_img = np.ones((new_height, new_width, 3), dtype=np.uint8) * 0  # 흰색 배경\n","            extended_img[:image.shape[0], :image.shape[1]] = image\n","            img_pil = Image.fromarray(extended_img)\n","            draw = ImageDraw.Draw(img_pil)\n","            #\n","        #\n","        # 배경 박스 그리기\n","        draw.rectangle([box_x0, box_y0, box_x1, box_y1], fill=background_color)\n","        #\n","        # 텍스트 그리기\n","        draw.text(position, text, font=font, fill=font_color)\n","        #\n","        return np.array(img_pil)\n","        #\n","    #\n","    @staticmethod\n","    # 이미지 확장 및 텍스트 추가 함수 (위쪽 확장)\n","    def extend_and_add_text_above(image, text, font_size, font_color=(255, 255, 255), background_color=(0, 0, 0)):\n","        # 이미지 크기 가져오기\n","        height, width, _ = image.shape\n","        #\n","        # 텍스트 크기 계산\n","        font = ImageFont.truetype(font_path, font_size)\n","        line_spacing = int(font_size * 1.5)\n","        text_lines = text.count('\\n') + 1\n","        total_text_height = line_spacing * text_lines\n","        #\n","        # 새 이미지 생성 (텍스트를 위한 공간 + 원본 이미지)\n","        extended_image = np.zeros((height + total_text_height + 20, width, 3), dtype=np.uint8)  # 검은색 배경\n","        extended_image[total_text_height + 20:, 0:width] = image\n","        #\n","        # 텍스트 추가\n","        extended_image_pil = Image.fromarray(extended_image)\n","        draw = ImageDraw.Draw(extended_image_pil)\n","        draw.rectangle([(0, 0), (width, total_text_height + 20)], fill=background_color)\n","        draw.text((10, 10), text, font=font, fill=font_color)\n","        #\n","        return np.array(extended_image_pil)\n","        #\n","    #\n","#\n","class AlignPro(ImageProcessor):\n","    @staticmethod\n","    def align_face(image, rect, landmaker):\n","        shape = landmaker(image, rect)\n","        coords = np.zeros((68, 2), dtype='int')\n","        #\n","        for i in range(0, 68):\n","            coords[i] = (shape.part(i).x, shape.part(i).y)\n","            #\n","        #\n","        eyes_center = np.mean(coords[36:48], axis=0).astype('int')\n","        eyes_center = (int(eyes_center[0]), int(eyes_center[1]))\n","        #\n","        dY = coords[45][1] - coords[36][1]\n","        dX = coords[45][0] - coords[36][0]\n","        angle = np.degrees(np.arctan2(dY, dX))\n","        #\n","        desired_right_eye_x = 1.0 - 0.35\n","        desired_dist = (desired_right_eye_x - 0.35)\n","        dist = np.sqrt((dX ** 2) + (dY ** 2))\n","        desired_dist *= 256\n","        scale = desired_dist / dist\n","        #\n","        M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n","        #\n","        tX = 256 * 0.5\n","        tY = 256 * 0.35\n","        M[0, 2] += (tX - eyes_center[0])\n","        M[1, 2] += (tY - eyes_center[1])\n","        #\n","        (w, h) = (256, 256)\n","        output = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n","        #\n","        return output\n","        #\n","    #\n","#\n","# 이미지 메타데이터 관리자 클래스 - SRP 및 캡슐화\n","class ImageMetadataManager:\n","    @staticmethod\n","    def copy_and_modify_image(image_path, destination_folder):\n","        save_name = os.path.basename(image_path)\n","        copied_image_path = os.path.join(destination_folder, save_name)\n","        os.makedirs(destination_folder, exist_ok=True)\n","        shutil.copy(image_path, copied_image_path)\n","        #\n","        with Image.open(copied_image_path) as thumb_im:\n","            if thumb_im.mode == 'RGBA':\n","                thumb_im = thumb_im.convert('RGB')\n","                #\n","            #\n","            o = io.BytesIO()\n","            thumb_im.thumbnail((50, 50), Image.ANTIALIAS)\n","            thumb_im.save(o, \"jpeg\")\n","            thumbnail = o.getvalue()\n","            #\n","            zeroth_ifd = {\n","                piexif.ImageIFD.Make: u\"oldcamera\",\n","                piexif.ImageIFD.XResolution: (96, 1),\n","                piexif.ImageIFD.YResolution: (96, 1),\n","                piexif.ImageIFD.Software: u\"piexif\",\n","                piexif.ImageIFD.Artist: u\"0!code\",\n","            }\n","            #\n","            exif_ifd = {\n","                piexif.ExifIFD.DateTimeOriginal: u\"2099:09:29 10:10:10\",\n","                piexif.ExifIFD.LensMake: u\"LensMake\",\n","                piexif.ExifIFD.Sharpness: 65535,\n","                piexif.ExifIFD.LensSpecification: ((1, 1), (1, 1), (1, 1), (1, 1)),\n","            }\n","            #\n","            gps_ifd = {\n","                piexif.GPSIFD.GPSVersionID: (2, 0, 0, 0),\n","                piexif.GPSIFD.GPSAltitudeRef: 1,\n","                piexif.GPSIFD.GPSDateStamp: u\"1999:99:99 99:99:99\",\n","            }\n","            #\n","            first_ifd = {\n","                piexif.ImageIFD.Make: u\"oldcamera\",\n","                piexif.ImageIFD.XResolution: (40, 1),\n","                piexif.ImageIFD.YResolution: (40, 1),\n","                piexif.ImageIFD.Software: u\"piexif\"\n","            }\n","            #\n","            exif_dict = {\"0th\": zeroth_ifd, \"Exif\": exif_ifd, \"GPS\": gps_ifd, \"1st\": first_ifd, \"thumbnail\": thumbnail}\n","            exif_bytes = piexif.dump(exif_dict)\n","            #\n","            thumb_im.save(copied_image_path, exif=exif_bytes)\n","            #\n","        #\n","        print(f\"{save_name} has been saved with modified metadata to {destination_folder}\")\n","        #\n","    #\n","    @staticmethod\n","    def print_exif_data(image_path):\n","        with Image.open(image_path) as im:\n","            exif_data = piexif.load(im.info['exif'])\n","            print(exif_data)\n","            #\n","        #\n","    #\n","#\n","# 얼굴 인식 시스템 클래스 - SRP, OCP, DIP 적용\n","class FaceRecognitionSystem:\n","    def __init__(self, config, detector_manager: FaceDetectionManager, predictor: Predictor, image_processor: ImageProcessor, metadata_manager: ImageMetadataManager):\n","        self.config = config\n","        self.detector_manager = detector_manager\n","        self.predictor = predictor\n","        self.image_processor = image_processor\n","        self.metadata_manager = metadata_manager\n","        #\n","    #\n","    def process_image(self, image_path, target_encodings):\n","        # 초기화\n","        predictions = []\n","        face_cnt = 0\n","        race_cnt = {'백인': 0, '흑인': 0, '아시아': 0, '중동': 0}\n","        male_cnt = 0\n","        #\n","        image = cv2.imread(image_path)\n","        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        #\n","        # 얼굴 검출 (리사이즈 전에 수행)\n","        faces = self.detector_manager.detect_faces(image, image_path) # 각각의 얼굴들이 모인 리스트\n","        font_size = max(12, int(image_rgb.shape[1] / 200)) # 이미지 크기에 따라 폰트 크기 조정\n","        #\n","        # 각 얼굴들을 순회\n","        for face in faces:\n","            x, y, x2, y2 = face\n","            face_width = x2 - x\n","            face_height = y2 - y\n","            #\n","            face_image = image_rgb[y:y2, x:x2]\n","            #\n","            encodings = face_recognition.face_encodings(image_rgb, [(y, x + face_width, y + face_height, x)]) # 얼굴 인코딩\n","            if not encodings:\n","                continue\n","                #\n","            #\n","            gaka = any(face_recognition.compare_faces(target_encodings, encodings[0], tolerance=0.3))\n","            #\n","            # FairFace 모델로 나이, 성별, 인종 예측\n","            race_pred, gender_pred, age_pred = self.predictor.predict(face_image)\n","            if race_pred is None or gender_pred is None or age_pred is None:\n","                print(f\"Skipping face at {x}, {y} due to insufficient data.\")\n","                continue\n","                #\n","            #\n","            race_text = ['백인', '흑인', '아시아', '중동'][race_pred]\n","            race_cnt[race_text] += 1\n","            gender_text, box_color = [('남성',(255, 100, 50)), ('여성',(50, 100, 255))][gender_pred]\n","            age_text = ['영아', '유아', '10대', '20대', '30대', '40대', '50대', '60대', '70+'][age_pred]\n","            male_cnt += 1 if gender_text == '남성' else 0\n","            #\n","            # 얼굴이 너무 작으면 예측 스킵\n","            if (face_width > 10 and face_height > 10):\n","                #\n","                # 가카\n","                if gaka and gender_text == '남성':\n","                    prediction_text = f'가카!'\n","                    box_color = (0, 255, 0)\n","                    #\n","                #\n","                else:\n","                    prediction_text = f\"{age_text}\"\n","                    #\n","                #\n","                all_text = f'^^^{race_text},{gender_text},{age_text},{prediction_text}'\n","                #\n","            #\n","            else:\n","                print(f\"Face at {x}, {y} is too small, skipping prediction.\")\n","                prediction_text = \"\"\n","                box_color = (0, 0, 0)\n","                all_text = \"\"\n","                #\n","            #\n","            predictions.append((x, y, x2 - x, y2 - y, box_color, prediction_text))\n","            #\n","            cv2_imshow(face_image)\n","            print(all_text)\n","            #\n","            face_cnt += 1\n","            #\n","        #\n","        # 이미지 해상도 일관성을 위해 리사이즈 및 패딩 추가\n","        image_rgb, scale, top, left = self.image_processor.resize_and_pad(image_rgb, 512)\n","        #\n","        for x, y, w, h, box_color, prediction_text in predictions:\n","            # 좌표를 리사이즈된 이미지에 맞게 조정\n","            x = int(x * scale) + left\n","            y = int(y * scale) + top\n","            w = int(w * scale)\n","            h = int(h * scale)\n","            #\n","            image_rgb = self.image_processor.draw_text_korean(image_rgb, prediction_text, (x, y), 15, font_color=(0, 0, 0), background_color=box_color)\n","            image_rgb = cv2.rectangle(image_rgb, (x, y), (x + w, y + h), box_color, 2)\n","            #\n","        #\n","        # 메타데이터 수정 및 이미지 저장\n","        if gaka:\n","            destination_folder = os.path.join(self.config['results_folder'], 'detection_target')\n","        else:\n","            destination_folder = os.path.join(self.config['results_folder'], 'detection_non_target')\n","        #\n","        # 사진 분석 결과 정보\n","        face_info = f\"검출된 인원 수: {face_cnt}명\\n\"\n","        gender_info = f\"남성: {male_cnt}명\\n여성: {face_cnt - male_cnt}명\\n\"\n","        race_info = \"\\n\".join([f\"{race}: {count}명\" for race, count in race_cnt.items() if count != 0])\n","        info = face_info + gender_info + race_info\n","        #\n","        image_rgb = self.image_processor.extend_and_add_text_above(image_rgb, info, font_size=font_size)\n","        #\n","        output_path = os.path.join(self.config['results_folder'], os.path.basename(image_path))\n","        #\n","        cv2.imwrite(output_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))\n","        self.metadata_manager.copy_and_modify_image(output_path, destination_folder)\n","        cv2_imshow(image_rgb)\n","        #\n","    #\n","#\n","# 메인 실행 모듈\n","def main():\n","    #\n","    base_drive_dir = '/content/gdrive/MyDrive/Ad/'\n","    #\n","    config = {\n","        \"dlib_model_path\"       : os.path.join(base_drive_dir, 'Model/DlibCNN/mmod_human_face_detector.dat'),\n","        \"landmark_path\"         : os.path.join(base_drive_dir, 'Model/DlibCNN/shape_predictor_68_face_landmarks.dat'),\n","        \"yolo_model_path\"       : os.path.join(base_drive_dir, 'Model/YOLOv8/yolov8n-face.pt'),\n","        \"fair_face_model_path\"  : os.path.join(base_drive_dir, 'FairFace/resnet34_fair_face_4.pt'),\n","        \"image_folder\"          : os.path.join(base_drive_dir, 'Image/test/test_park_mind_problem'),\n","        \"pickle_path\"           : os.path.join(base_drive_dir, 'Embedings/FaceRecognition(ResNet34).pkl'),\n","        \"results_folder\"        : os.path.join(base_drive_dir, 'results')\n","    }\n","    #\n","    # 얼굴 탐지기, 예측기, 이미지 프로세서, 메타데이터 관리자 생성\n","    detector_manager = FaceDetectionManager([\n","        DlibFaceDetector(config['dlib_model_path']),\n","        YOLOFaceDetector(config['yolo_model_path']),\n","        MTCNNFaceDetector()\n","    ])\n","    #\n","\n","\n","    # 얼굴 예측기 생성\n","    predictor = FairFacePredictor(config['fair_face_model_path'])\n","    #\n","    # 이미지 프로세서, 메타데이터 관리자 생성\n","    image_processor = ImageProcessor()\n","    metadata_manager = ImageMetadataManager()\n","    #\n","    # 얼굴 인식 시스템 생성\n","    face_recognition_system = FaceRecognitionSystem(config, detector_manager, predictor, image_processor, metadata_manager)\n","    #\n","    # 타겟 얼굴 인코딩 로드\n","    with open(config['pickle_path'], 'rb') as f:\n","        target_encodings = np.array(pickle.load(f))\n","        #\n","    #\n","    # 이미지 폴더에서 이미지 로드\n","    image_list = [f for f in os.listdir(config['image_folder']) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n","    random_images = random.sample(image_list, 1)\n","    for image in image_list:\n","        image_path = os.path.join(config['image_folder'], image)\n","        face_recognition_system.process_image(image_path, target_encodings)\n","        print(f\"Processed {image_path}\")\n","        #\n","    #\n","#\n","if __name__ == \"__main__\":\n","    # 폰트 경로는 전역 변수\n","    font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n","    main()\n","    #\n","#"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
